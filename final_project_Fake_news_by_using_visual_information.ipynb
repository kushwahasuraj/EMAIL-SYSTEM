{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final project Fake news by using visual information.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EyHzJob8YlhAaQ_MV9sLbvpMDdFDUZtP",
      "authorship_tag": "ABX9TyNo9IvqGgioPHXq+lJYrmdh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushwahasuraj/EMAIL-SYSTEM/blob/master/final_project_Fake_news_by_using_visual_information.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_CbB1B0f-PC",
        "outputId": "b77bf421-109b-49c9-8fcc-b8af44d45c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras import backend as K\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import keras\n",
        "!pip install keras_applications\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape # this will work for older versions of keras. 2.2.0 or before\n",
        "from tensorflow.keras.utils import get_source_inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEp4QvDa_17Y",
        "outputId": "df775747-112e-4874-95ab-b5bfbe626ca5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def VGGupdated(input_tensor=None,classes=2):    \n",
        "   \n",
        "    img_rows, img_cols = 300, 300   # by default size is 224,224\n",
        "    img_channels = 3\n",
        "\n",
        "    img_dim = (img_rows, img_cols, img_channels)\n",
        "   \n",
        "    img_input = Input(shape=img_dim)\n",
        "    \n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    # Classification block\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "    x = Dense(classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    # Create model.\n",
        "   \n",
        "     \n",
        "    model = Model(inputs = img_input, outputs = x, name='VGGdemo')\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "JdCevbMNgL3_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGGupdated(classes = 2) # fake and real"
      ],
      "metadata": {
        "id": "vyxOGl4JgT__"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hdGC8LjhgZbW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "dataset_path = os.listdir('/content/drive/MyDrive/Colab Notebooks/news_dataset')\n",
        "\n",
        "news_types = os.listdir('/content/drive/MyDrive/Colab Notebooks/news_dataset')\n",
        "print (news_types)  #what kinds of news are in this dataset\n",
        "\n",
        "print(\"Types of news found: \", len(dataset_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwbebLOigewG",
        "outputId": "0806a3ea-3dea-4013-95c3-df010d7ac6ff"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['real', 'fake']\n",
            "Types of news found:  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news = []\n",
        "\n",
        "for item in news_types:\n",
        "    # Get all the file names\n",
        "    all_news = os.listdir('/content/drive/MyDrive/Colab Notebooks/news_dataset' + '/' +item)\n",
        "\n",
        " # Add them to the list\n",
        "    for  images in all_news:\n",
        "        news.append((item, str('/content/drive/MyDrive/Colab Notebooks/news_dataset' + '/' +item) + '/' + images))\n",
        "        print(news)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppHeJnKFhcbY",
        "outputId": "6839275f-7ce0-402b-e294-b0ad301874ff"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a dataframe        \n",
        "news_df = pd.DataFrame(data=news, columns=['label', 'image'])\n",
        "print(news_df.head())\n",
        "#print(news_df.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQqkw4dhhi8M",
        "outputId": "3516c166-8b8c-4563-d7ee-890d72715c05"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                              image\n",
            "0  real  /content/drive/MyDrive/Colab Notebooks/news_da...\n",
            "1  real  /content/drive/MyDrive/Colab Notebooks/news_da...\n",
            "2  real  /content/drive/MyDrive/Colab Notebooks/news_da...\n",
            "3  real  /content/drive/MyDrive/Colab Notebooks/news_da...\n",
            "4  real  /content/drive/MyDrive/Colab Notebooks/news_da...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of news in the dataset: \", len(news_df))\n",
        "news_count = news_df['label'].value_counts()\n",
        "\n",
        "print(\"rooms in each category: \")\n",
        "print(news_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1gHEFhbhoBz",
        "outputId": "10bce649-36c2-4717-e91e-f9d0f04d616a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of news in the dataset:  332\n",
            "rooms in each category: \n",
            "real    204\n",
            "fake    128\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('NEWS ANALYSIS')\n",
        "plt.xlabel('label')\n",
        "plt.ylabel('news_Counts')\n",
        "news_df['label'].value_counts().plot(kind=\"bar\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "a-FichPrcbfW",
        "outputId": "a4d1ef97-2a4c-4711-a933-608baaa262d0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/news_dataset/'\n",
        "im_size = 300\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "count = 0\n",
        "\n",
        "for i in news_types:\n",
        "    data_path = path + str(i) \n",
        "    filenames = [i for i in os.listdir(data_path) ]\n",
        "   \n",
        "    for f in filenames:\n",
        "        image_exists = os.path.isfile(data_path + '/' + f)\n",
        "        \n",
        "        if image_exists:\n",
        "            img = cv2.imread(data_path + '/' + f)\n",
        "            dim = (im_size, im_size)\n",
        "            img = cv2.resize(img, dim)\n",
        "        else:\n",
        "            print('Wrong path:', data_path + '/' + f)\n",
        "        \n",
        "        images.append(img)\n",
        "        labels.append(i)\n"
      ],
      "metadata": {
        "id": "F7gX50XwhqxX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(images)\n",
        "images = images.astype('float32') / 255.0\n",
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO8XptgHh9DL",
        "outputId": "caed1d53-2c5a-41c4-fe08-ded1ecec245d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(332, 300, 300, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
        "y=news_df['label'].values\n",
        "#print(y[:5])"
      ],
      "metadata": {
        "id": "i7QXZyQeiBcD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_labelencoder = LabelEncoder ()\n",
        "y = y_labelencoder.fit_transform (y)\n",
        "print (y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt9BPY2ziEQw",
        "outputId": "6df9c0b8-7f70-4c6b-acd3-04aea4b0fe38"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer # Here is the one\n",
        "y=y.reshape(-1,1)\n",
        "#onehotencoder = OneHotEncoder(categorical_features=[0])  #Converted  scalar output into vector output where the correct class will be 1 and other will be 0\n",
        "onehotencoder = ColumnTransformer([(\"images\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
        "Y= onehotencoder.fit_transform(y)\n",
        "Y.shape  #(381, 2)"
      ],
      "metadata": {
        "id": "HoNDP3KaiHYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262dc788-8500-484a-b9e9-83aefe710425"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(332, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "images, Y = shuffle(images, Y, random_state=1)\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.05, random_state=415)\n",
        "\n",
        "#inpect the shape of the training and testing.\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7DjTodUiRno",
        "outputId": "4dcd5987-35b7-4c1c-f30c-7e93fc51262d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(315, 300, 300, 3)\n",
            "(315, 2)\n",
            "(17, 300, 300, 3)\n",
            "(17, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "histroy =model.fit(train_x, train_y,epochs=10,batch_size = 63)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U-9Z25CniW6C",
        "outputId": "ce7b6ab7-41ee-4009-8ddc-cbaa6b583a15"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-4bfd5a455d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistroy\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m63\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'VGGdemo/block2_conv2/Conv2D' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n      self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-36-a39adafefd33>\", line 1, in <module>\n      histroy =model.fit(train_x, train_y, epochs = 10, batch_size = 63)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py\", line 240, in convolution_op\n      name=self.__class__.__name__)\nNode: 'VGGdemo/block2_conv2/Conv2D'\nOOM when allocating tensor with shape[63,128,150,150] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node VGGdemo/block2_conv2/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3977]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title(\"Loss Function\")\n",
        "plt.ylabel(\"Accuracy and Loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r6yC9W7myxQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PUbROeiRXH0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Take input from User and Classify that image"
      ],
      "metadata": {
        "id": "vEj7sjwVwECg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import imread\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "img_path = '/content/drive/MyDrive/test1.jpg'\n",
        "\n",
        "img = image.load_img(img_path, target_size=(300, 300))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "print('Input image shape:', x.shape)\n",
        "\n",
        "my_image = imread(img_path)\n",
        "imshow(my_image)"
      ],
      "metadata": {
        "id": "2eSfaF7EwEsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x)\n",
        "y_pred\n",
        "y1 = y_pred[0][0]\n",
        "y2 = y_pred[0][1]\n",
        "\n",
        "if(y1 < y2):\n",
        "  pred = 'Fake Image'\n",
        "else:\n",
        "  pred = 'Real Image'  \n",
        "\n",
        "print(\"Our model says it is :\", pred) "
      ],
      "metadata": {
        "id": "QqMWx1QrwTWN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}